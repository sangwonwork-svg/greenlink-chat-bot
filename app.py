import streamlit as st
from groq import Groq
import fitz  # PDFìš©
from pptx import Presentation  # PPTXìš©
import pandas as pd  # Excelìš©
import os
import olefile # HWPìš©

# --- 1. ë³´ì•ˆ ì„¤ì • ---
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

st.set_page_config(page_title="ì†Œê·œëª¨ì§€ì›ì‚¬ì—…IoT ì±—ë´‡", layout="wide")

# --- 2. íŒŒì¼ í†µí•© ë¡œì§ (ìºì‹±) ---
@st.cache_resource
def load_all_documents():
    combined_text = ""
    file_list = []
    target_extensions = (".pdf", ".pptx", ".txt", ".hwp", ".xlsx", ".xls")
    exclude_files = ("requirements.txt", "app.py", "packages.txt")
    
    for file in os.listdir("."):
        if file.lower().endswith(target_extensions) and file not in exclude_files and not file.startswith("."):
            try:
                if file.lower().endswith(".pdf"):
                    doc = fitz.open(file)
                    for page in doc:
                        combined_text += page.get_text() + "\n"
                elif file.lower().endswith(".pptx"):
                    prs = Presentation(file)
                    for slide in prs.slides:
                        for shape in slide.shapes:
                            if hasattr(shape, "text"):
                                combined_text += shape.text + "\n"
                elif file.lower().endswith((".xlsx", ".xls")):
                    df_dict = pd.read_excel(file, sheet_name=None)
                    for sheet_name, df in df_dict.items():
                        combined_text += f"\n[ì‹œíŠ¸: {sheet_name}]\n{df.to_string(index=False)}\n"
                elif file.lower().endswith(".txt"):
                    with open(file, "r", encoding="utf-8") as f:
                        combined_text += f.read() + "\n"
                elif file.lower().endswith(".hwp"):
                    if olefile.isOleFile(file):
                        ole = olefile.OleFileIO(file)
                        if "PrvText" in ole.listdir():
                            combined_text += ole.openstream("PrvText").read().decode("utf-16") + "\n"
                file_list.append(file)
            except Exception as e:
                st.sidebar.error(f"{file} ì½ê¸° ì‹¤íŒ¨: {e}")
    return combined_text, file_list

knowledge_base, learned_files = load_all_documents()

# --- 3. ì‚¬ì´ë“œë°” êµ¬ì„± ---
with st.sidebar:
    st.title("ğŸ“š í•™ìŠµëœ ë¬¸ì„œ ëª©ë¡")
    st.info(f"ì´ {len(learned_files)}ê°œ ë¬¸ì„œ í•™ìŠµ ì™„ë£Œ")
    if learned_files:
        for i, name in enumerate(sorted(learned_files), 1):
            st.write(f"{i}. {name}")
    st.divider()
    if st.button("ğŸ”„ ì§€ì‹ ìƒˆë¡œê³ ì¹¨"):
        st.cache_resource.clear()
        st.rerun()

# --- 4. ì±—ë´‡ UI ---
st.title("ğŸ¤– ì†Œê·œëª¨ì§€ì›ì‚¬ì—…IoT ì±—ë´‡")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        client = Groq(api_key=GROQ_API_KEY)
        
        # ë¬´ë£Œ í† í° í•œë„(TPM)ë¥¼ ê³ ë ¤í•˜ì—¬ ì•ˆì „í•˜ê²Œ 15,000ì ë‚´ì™¸ë¡œ ì¡°ì ˆ
        # 8B ëª¨ë¸ì€ ì´ ì •ë„ ë¶„ëŸ‰ë„ ì¶©ë¶„íˆ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        context_text = knowledge_base[:15000] 
        
        messages = [
            {
                "role": "system", 
                "content": f"ë„ˆëŠ” ì†Œê·œëª¨ì§€ì›ì‚¬ì—…IoT ì „ë¬¸ê°€ì•¼. ì•„ë˜ ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜. ë¬¸ì„œì— ì—†ìœ¼ë©´ ëª¨ë¥¸ë‹¤ê³  í•´.\n\n[ë¬¸ì„œ ë‚´ìš©]\n{context_text}"
            }
        ]
        # ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ ìµœê·¼ ëŒ€í™” 3ê°œë§Œ í¬í•¨ (í† í° ì ˆì•½)
        for m in st.session_state.messages[-3:]:
            messages.append({"role": m["role"], "content": m["content"]})

        with st.spinner("ë‹µë³€ ì¤‘..."):
            try:
                completion = client.chat.completions.create(
                    messages=messages,
                    model="llama-3.1-8b-instant", # ê°€ì¥ ë„ë„í•œ ë¬´ë£Œ ëª¨ë¸
                    temperature=0.1,
                )
                answer = completion.choices[0].message.content
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
